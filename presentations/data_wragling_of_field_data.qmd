---
title: "Data wrangling with field data"
date: last-modified
author: "David Jansen"
execute:
  include: true
  echo: true
format:
  revealjs: 
    theme: sky
    css: ../styles.css
    reveal_plugins: notes
    mathjax: NULL
---

## Background

For the Terminix project of Zack student collected tick count data in the the yard of peoples houses. This data was collected on a standardize datasheet.

## Background

![](figures/empty_sheet_Page_1.jpg){fig-align="center"}

## Background

On the top of the datasheet there was a line for some metadata such as date, time, weather and name of people collecting the data.

The rest of the form had space to note the counts of 2 tick species in 3 different life stages. There were 4 transects and every zone has 4 sections. So it total there were 4 \* 4 \* 2 \* 3 = 96 counts per yard per visit.

The files would be saved with as a csv file with the house number, date (mm_dd_yy) and experiment stage in the name. For example 012_07_12_23_pretreatment.

## Background of code

The aim of the code I was writing was to open all the files, extract both the metadata and the count data and combine all of it into a large file.

An early test of the code on a few of the sheets went well and worked as expected.

## The fun begins

-   get R setup
-   slightly complicated way of opening packages
-   makes sharing code easier

```{r, echo = TRUE}
## Code to open the datasheets of the project
packages <- c("tidyverse"
              , "cellranger"
              , "data.table"
              , "janitor"
              , "purrr"
              , "readxl")

## install packages if needed and open libraries
if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
  install.packages(setdiff(packages, rownames(installed.packages())), 
                   dependencies = TRUE)}  

invisible(lapply(packages, library, character.only = TRUE, 
                 warn.conflicts = TRUE, quietly =TRUE))
```

## find files

-   Spaces in the path :-(
-   Remember ***No Spaces :-)***

```{r}
## all the datasheets are in a folder on Box
## on my computer this is at 
## C:\Users\dajansen3\Box\All data sheet entries EC 2023
## adapt to your path

sheet_folder = "C://Users//dajansen3//Box//All data sheet entries EC 2023//"  
```

## The importance of consistency

```{r}
tibble(filename = list.files(path = sheet_folder)[c(4, 164, 876, 992,  200)]) 
```

-   dates are in many formats

-   this makes writing general code hard

-   For now I'll work with these, but all fix (manually by Zack)

## Lets open some data (1)

-   The files have a few lines with metadata.

-   These should not be loaded for count data

-   Using the skip option to exclude the first 4 lines

-   For the count data the first column is also not need.

-   Only the 2nd to 6th column contain data on tick counts

## Lets open some data (2)

```{r}
read_csv(list.files(path = sheet_folder, full.names = TRUE)[2], 
         skip = 4, col_select = c(2:6))
```

-   yeah that looks good, but...

## Lets open some data (3)

```{r}
read_csv(list.files(path = sheet_folder, full.names = TRUE)[3], 
         skip = 4, col_select = c(2:6))
```

-   what is happening here?
-   extra lines of white space?

> -   Some troubleshooting will be needed

## Metadata

Looking at the metadata for the same two files

```{r}
read_csv(list.files(path = sheet_folder, full.names = TRUE)[2], n_max = 1)
```

------------------------------------------------------------------------

```{r}
read_csv(list.files(path = sheet_folder, full.names = TRUE)[3], n_max =1)
```

Looks ok and we will get back to the metadata later

## Open all datafiles

-   Aim: all datasheets and combine into one data file.
-   We are going to make a function to read the data

```{r}
all_datasheets <- list.files(path = sheet_folder) 

read_data_v1 = function(filepath) {     ## hint v1 is suggesting there are going to be more :-)
  #print(filepath) ## can help to find issues
  read_csv(filepath, ## path to specific file,
           skip = 4, ## skip first 4 rows
           col_select = c(2:6),  ## select column 2 to 6
           show_col_types = FALSE, ## don't show the message,,
           name_repair = "minimal" ## don't try and repair names
           )
}
```

## Reading data (v1)

```{r}
tibble(datasheet = all_datasheets) %>%
  mutate(path_to_sheet = paste0(sheet_folder, datasheet)) %>% 
  slice(c(1:2)) %>% ## lest first try it 2
  mutate(data = map(.x = path_to_sheet, .f = read_data_v1)) %>% 
  select(-path_to_sheet) %>% 
  ## counting lines as a quick check
  mutate(nr_rows_in_tibble = map_dbl(.x = data, .f = nrow)) 
```

!!! Yeah that worked !!!

## Reading data (v1)

Now on all of them.

```{r, eval = TRUE}
#| error: true

tibble(datasheet = all_datasheets) %>%
  mutate(path_to_sheet = paste0(sheet_folder, datasheet)) %>%    
  mutate(data = map(.x = path_to_sheet, .f = read_data_v1)) %>% 
  mutate(nr_rows_in_tibble = map_dbl(.x = data, .f = nrow)) 
```

Boo an error

## Troubleshooting (1a)

-   What is happening?
-   Troubleshooting code/data
    -   Errors stop the running of code. This can make troubleshooting hard.
    -   The purrr package has a function that can keep code running.
    -   Temporarily give an alternative outcome.

```{r}
## purrr function
## give the function to run and an alternative answer in case of error
read_data_possibly_v1 <- purrr::possibly(.f = read_data_v1,  
                                         otherwise = tibble())  

```

## Troubleshooting (1b)

-   rerun code
-   problem sheets have an empty tibble and 0 rows

```{r}
tibble(datasheet = all_datasheets) %>%
  slice(1:10) %>% 
  mutate(path_to_sheet = paste0(sheet_folder, datasheet)) %>% 
  mutate(data = map(.x = path_to_sheet, .f = read_data_possibly_v1)) %>% 
  mutate(nr_rows_in_tibble = map_dbl(.x = data, .f = nrow)) %>% 
  select(-path_to_sheet)
```

## Troubleshooting (1c)

-   All the ones with 0 have a problem
-   Let's have a look at on of them.

## Troubleshooting (1b)

```{r, eval = FALSE}
tibble(datasheet = all_datasheets) %>% 
  slice(3) %>% 
  mutate(path_to_sheet = paste0(sheet_folder, datasheet)) %>% 
  pull(path_to_sheet) %>% 
  shell.exec()
```

[Open an example problem filel](https://uwmadison.box.com/s/7tfrmpuhn5rex3sdes0j9uc73zpr9wiv "Example problem file")

-   extra lines of white space
-   need to update the read function to deal with this
-   after a lot of trial and error, I found the fread function from the data.table package could deal with this

## Troubleshooting (1d)

```{r}
read_data_v2 = function(filepath) { 
  ## hint v2 is suggesting there are going to be more :-)
  fread(filepath 
        , header = TRUE 
        , skip = "transect"  ## only start reading file after transect
        , select = 2:6  ## selected columns
        , blank.lines.skip = TRUE ## skip and empty lines
  ) %>% 
    as_tibble() 
}

read_data_possibly_v2 <- purrr::possibly(.f = read_data_v2, otherwise = tibble())
```

## Troubleshooting (1e)

```{r}
tibble(datasheet = all_datasheets) %>% 
  slice(1:10) %>% 
  mutate(path_to_sheet = paste0(sheet_folder, datasheet)) %>% 
  mutate(data = map(.x = path_to_sheet, .f = read_data_possibly_v2)) %>% 
  mutate(nr_rows_in_tibble = map_dbl(.x = data, .f = nrow))
```

-   better but there is still an problem

## Troubleshooting (2a)

-   all files should be csv

```{r}
tibble(datasheet = all_datasheets) %>% 
  slice(1:10) %>% 
  mutate(path_to_sheet = paste0(sheet_folder, datasheet)) %>% 
  mutate(data = map(.x = path_to_sheet, .f = read_data_possibly_v2)) %>% 
  mutate(nr_rows_in_tibble = map_dbl(.x = data, .f = nrow)) %>% 
  filter(nr_rows_in_tibble == 0) %>% 
  select(path_to_sheet) %>%  pull() %>% 
  read_lines()
```

-   but this looks like an excel file?

## Troubleshooting (2a)

![](figures/frustrated_coder.jpg){fig-align="center"}

## Troubleshooting (2b)

```{r, eval = FALSE}
shell.exec(paste0(sheet_folder, "001_6_22_23_PostTreatment2.csv"))
```

[Open 001_6_22_23_PostTreatment2.csv in excel](https://uwmadison.box.com/s/cje1y0nietw7hqz7ntibj4dn70x0s75f "Example excel sheet")

## Troubleshooting (2c)

-   Lets open it as an excel file

```{r}
read_excel(paste0(sheet_folder, "001_6_22_23_PostTreatment2.csv"), skip = 4)
```

> -   fun!! we have Excel files with a csv extension
> -   I'll also share now that there are real Excel files with an xlsx extension

## Troubleshooting (2d)

::: nonincremental
-   To solve it we first need to know which files are:

1.  real csv
2.  real excel files
3.  excel files with csv extension
:::

> -   We can use the purrr possible from earlier.

## Troubleshooting (2e)

-   With files are 'fake' csv files

```{r}
excel_files_with_csv_extension <- tibble(datasheet = all_datasheets) %>% 
  mutate(path_to_sheet = paste0(sheet_folder, datasheet)) %>% 
  mutate(data = map(.x = path_to_sheet, .f = read_data_possibly_v2)) %>% 
  mutate(nr_rows_in_tibble = map_dbl(.x = data, .f = nrow)) %>% 
  ## filter all the ones with 0s as these are mistakes
  filter(nr_rows_in_tibble == 0) %>% 
  select(datasheet) %>% ## select only the datasheet names  
  pull() ## and pull these into a vector

excel_files_with_csv_extension[1:10]
```

There are `r excel_files_with_csv_extension %>% length()` csv files that actually are excel files.

## Troubleshooting (2f)

-   Updates to the function to also load excel files

```{r}
read_data_v3 = function(filetype, filepath) { 
  if(filetype == "csv") { 
    data.table::fread(filepath
                      , header = TRUE
                      , skip = "transect"
                      , select = 2:6
                      , blank.lines.skip = TRUE
                      ) 
    } else { 
      read_excel(filepath, skip = 4) %>% 
        select(transect, section, tick_species, tick_stage, tick_count)
    } ## end of else 
  } ## end of function

read_data_possibly_v3 <- purrr::possibly(.f = read_data_v3, otherwise = tibble())
```

## Troubleshooting (2d)

```{r}
tibble(datasheet = all_datasheets) %>% 
  slice(1:10) %>% 
  mutate(path_to_sheet = paste0(sheet_folder, datasheet)) %>% 
  mutate(filetype = if_else(str_detect(datasheet, "csv"), "csv", "xlsx")) %>% 
  ## if a file is part of the 'fake' list change the extension
  mutate(real_filetype = if_else(condition =datasheet %in% excel_files_with_csv_extension
                                 , true  = 'xlsx'
                                 , false = filetype)) %>% 
  mutate(data = map2(.x = real_filetype,  ## map2 needs two inputs
                     .y = path_to_sheet, 
                     .f = read_data_possibly_v3)) %>% 
  mutate(nr_rows_in_tibble = map_dbl(.x = data, .f = nrow)) %>% 
  select(- path_to_sheet)
```

## Troubleshooting (2e)

-   Looks like we are getting somewhere
-   Next step is to combine all the sheets

```{r}
combined_sheets <- tibble(datasheet = all_datasheets) %>% 
  mutate(path_to_sheet = paste0(sheet_folder, datasheet)) %>% 
  mutate(filetype = if_else(str_detect(datasheet, "csv"), "csv", "xlsx")) %>% 
  mutate(real_filetype = if_else(datasheet %in% excel_files_with_csv_extension, 
                                 'xlsx', filetype)) %>% 
  mutate(data = map2(.x = real_filetype, .y = path_to_sheet, 
                     .f = read_data_possibly_v3)) %>% 
  mutate(nr_rows_in_tibble = map_dbl(.x = data, .f = nrow))

```

<!-- ## Troubleshooting (2f) -->

<!-- - On every sheets with should have 4 zones with 4 sections and data on 2 tick species with 3 life stages; -->

<!-- `4 * 4 * 2 * 3 = 96` -->

<!-- ```{r} -->

<!-- combined_sheets %>% filter(nr_rows_in_tibble != 96)  -->

<!-- ``` -->

<!-- Ok there will be 2 files that will need checking -->

<!-- ```{r} -->

<!-- combined_sheets %>%  -->

<!--   filter(nr_rows_in_tibble == 95) %>%  -->

<!--   unnest(cols = c(data)) %>%   -->

<!--   group_by(transect) %>%  -->

<!--   summarise(n())  -->

<!-- ``` -->

<!-- - More manually checks (go back to data sheets) -->

## Are we there?

```{r}
#| error: true
combined_sheets %>% 
  unnest(cols = c(data))
```

-   Unfortunately we have another sigh moment.
-   Reason is that we have two data types in one column.

## Quick reminder

-   The full content of columns in R need to be in same data type and units

    -   character (e.g, "a", "swc")

    -   numeric (real or decimal) (e.g, 2, 2.0)

    -   logical (FALSE, TRUE)

    -   integer (e.g, 2L, as.integer(3))

    -   complex (e.g, 1 + 0i, 1 + 4i) \<- These can be annoying

## Troubleshooting (3a)

```{r}
combined_sheets_temp <- combined_sheets %>% 
  mutate(temp_data = map(.x = data, 
  ## turn all the columns to character                         
                         .f = mutate_all, as.character)) 

combined_sheets_temp %>% 
  select(datasheet, temp_data) %>% 
  unnest(cols = c(temp_data)) %>% 
  ## turn the tick count column back to numeric
  ## if this doesn't work the cell will turn into NA
  mutate(temp_count = as.numeric(tick_count)) %>% 
  filter(!is.na(tick_count)) %>% 
  filter(is.na(temp_count))
```

## Troubleshooting (3a)

What are the non-numeric values?

```{r}
## ok there are cells that have different values then NA or a number
combined_sheets_temp %>% 
  select(datasheet, temp_data) %>% 
  unnest(cols = c(temp_data)) %>% 
  mutate(temp_count = as.numeric(tick_count)) %>% filter(is.na(temp_count)) %>% 
  select(tick_count) %>% distinct() %>% pull()
```

## Troubleshooting (3b)

-   Multiple NA values
-   Tell R about these NA values
-   We could use mutate, but better to adapt function.

```{r}
read_data_v4 = function(filetype, filepath) {
  if(filetype == "csv") {
    data.table::fread(filepath , header = TRUE , skip = "transect"
                      , select = 2:6, blank.lines.skip = TRUE, 
                      na.strings = c(NA, "N/A", "NA", "Na", "nA", "N.A")) 
    } else { 
      read_excel(filepath , skip = 4 , 
                 na = c("N/A", "NA", "Na", "nA", "N.A"), 
                 .name_repair = "unique_quiet", progress = FALSE) %>% 
        select(transect, section, tick_species, tick_stage, tick_count) 
    }
}
  
read_data_possibly_v4 <- purrr::possibly(.f = read_data_v4, 
                                         otherwise = tibble())
```

```{r, include = FALSE}
combined_sheets <- tibble(datasheet = all_datasheets) %>% 
  mutate(path_to_sheet = paste0(sheet_folder, datasheet)) %>% 
  mutate(filetype = if_else(str_detect(datasheet, "csv"), "csv", "xlsx")) %>% 
  mutate(real_filetype = if_else(datasheet %in% excel_files_with_csv_extension, 
                                 'xlsx', filetype)) %>% 
  mutate(data = map2(.x = real_filetype, .y = path_to_sheet, 
                     .f = read_data_possibly_v4)) %>% 
  mutate(nr_rows_in_tibble = map_dbl(.x = data, .f = nrow))

```

## Troubleshooting (3c)

Lets look at the other values?

```{r}
combined_sheets_temp %>% 
  select(datasheet, temp_data) %>% 
  unnest(cols = c(temp_data)) %>% 
  filter(tick_count %in% (c("20+", "1(M)", "1(F)", "1 (F)", "1pm")))
```

## Troubleshooting (3c) tbd

```{r, include = TRUE}
temp_exclude <- combined_sheets_temp %>% 
  select(datasheet, temp_data) %>% 
  unnest(cols = c(temp_data)) %>% 
  filter(tick_count %in% (c("20+", "1(M)", "1(F)", "1 (F)", "1pm"))) %>% 
  select(datasheet) %>% 
  pull()

temp_exclude
```

Since there are just a few, it probably is easiest/best to fix by hand. To be save make a comment or keep a raw raw version.

## Troubleshooting (3d)

```{r}
#| error: true
combined_sheets %>% 
  filter(!(datasheet %in% temp_exclude)) %>% ## temp excluding the problem sheets
  unnest(cols = c(data))
```

So after we fix the alternative numbers it should work.

## Final function

```{r}
## final function
read_data_coundata = function(filetype, filepath) {
  if(filetype == "csv") {
    data.table::fread(filepath , header = TRUE , skip = "transect"
                      , select = 2:6, blank.lines.skip = TRUE,
                      , na.strings = c(NA, "N/A", "NA", "Na", "nA", "N.A"))
    } else {
      read_excel(filepath, skip = 4,
                 na = c("N/A", "NA", "Na", "nA", "N.A"), 
                 .name_repair = "unique_quiet", progress = FALSE) %>% 
        select(transect, section, tick_species, tick_stage, tick_count)
    }
}
```

# Metadata

## Metadata

-   first two lines contain metadata regarding the houses
-   besides the header row there is only 1 line of data
-   as a reminder

```{r}
read_csv(list.files(path = sheet_folder, full.names = TRUE)[2], n_max = 1)
```

## Metadata

-   so only one row of data and we have need all 12 column
-   we know now that not all files are simply csv with a fixed structure
-   lets see if we can adapt the last version of the read_data function

```{r}
read_metadata_v1 = function(filetype, filepath) { ## can we do it with 1 version? 
  if(filetype == "csv") {
    data.table::fread(filepath,  header = TRUE, blank.lines.skip = TRUE
                      , na.strings = c(NA, "N/A", "NA", "Na", "nA", "N.A")
                      #, .name_repair = "unique_quiet",
                      , check.names = TRUE
                      , nrows = 1) ## besides the header we only want 1 row
    } else { read_excel(filepath 
                        , na = c("N/A", "NA", "Na", "nA", "N.A") 
                        , n_max = 1 )
    }
  }
```

## Metadata

-   first with a few

```{r}
#| error: true
temp_metadata <- tibble(datasheet = all_datasheets) %>% 
  mutate(path_to_sheet = paste0(sheet_folder, datasheet)) %>% 
  mutate(filetype = if_else(str_detect(datasheet, "csv"), "csv", "xlsx")) %>% 
  mutate(real_filetype = if_else(datasheet %in% excel_files_with_csv_extension, 
                                 'xlsx', filetype)) %>% 
  mutate(metadata = map2(.x = real_filetype, .y = path_to_sheet, 
                         .f = read_metadata_v1))  
  
temp_metadata %>% 
  slice(1:10) %>% 
  unnest(cols = c(metadata))
```

Again a conflict between datatypes in a column

## Troubleshooting (3b)

```{r, eval= FALSE}
#| error: true
temp_metadata %>% 
  slice(1:10) %>% 
  mutate(temp_metadata = map(.x = metadata, .f = mutate_all, as.character)) %>% 
  select(datasheet, temp_metadata) %>% 
  unnest(cols = c(temp_metadata))
```

## Troubleshooting (3b)

```{r, echo = FALSE}
library(flextable)
temp_metadata %>% 
  slice(1:10) %>% 
  mutate(temp_metadata = map(.x = metadata, .f = mutate_all, as.character)) %>% 
  select(datasheet, temp_metadata) %>% 
  unnest(cols = c(temp_metadata)) %>% 
  select(-datasheet) %>% 
  flextable() %>% 
  bg(bg="white", part = "all") %>% 
  bg(i = c(2), j = c(6), bg="red") 
```

-   it only complained about temp, but I also see issues in other variables
-   Any suggestions on what they are ?

## Troubleshooting (3c)

```{r, echo = FALSE}
library(flextable)
temp_metadata %>% 
  slice(1:10) %>% 
  mutate(temp_metadata = map(.x = metadata, .f = mutate_all, as.character)) %>% 
  select(datasheet, temp_metadata) %>% 
  unnest(cols = c(temp_metadata)) %>% 
  select(-datasheet) %>% 
  flextable() %>% 
  bg(bg="white", part = "all") %>% 
  bg(i = c(2), j = c(2), bg="red") %>% 
  bg(i = c(10), j = c(2:4), bg="red") %>% 
  bg(i = c(2), j = c(6), bg="red") %>% 
  bg(i = c(1,2), j = c(7), bg="red") 
```

## Troubleshooting (3d)

-   lets go ahead and run open all the data
    -   data is still all character
    -   do we have big issues?
    -   or just a few that we can fix manually

```{r, echo = FALSE}
check_metadata <- temp_metadata %>% 
  mutate(temp_metadata = map(.x = metadata, .f = mutate_all, as.character)) %>% 
  unnest(cols = c(temp_metadata))
```

First it seem to have 2 extra columns lets check those first

```{r}
check_metadata %>%  slice(1:5)
```

## Troubleshooting (3e)

```{r}
check_metadata %>% filter(!is.na(Temp)) %>% 
  select(datasheet, house, temp, Temp) 
```

Ok, so Temp is temp, lets fix it

```{r}
step1 <- check_metadata %>% mutate(temp = if_else(condition = is.na(temp)
                                                  , true = Temp
                                                  , false = temp)) %>% 
  select(-Temp) ## remove the extra column
```

## Troubleshooting (3f)

Now the checking ...1 and fixing it.

```{r}
step1 %>% filter(!is.na(...1))   

step1 %>% filter(!is.na(...1))  %>% 
  select(datasheet, house, ...1) 

step2 <- step1 %>% mutate(house = if_else(is.na(house), ...1, house)) %>%
  select(-...1)
```

## Troubleshooting (3g)

-   Next we check why not all temp is numeric

```{r}
#| error: true
step2 %>% mutate(temp_numeric = as.numeric(temp))
```

-   I had no idea what that means
-   has something to do with a non standard character (thanks Google)
-   you can find them by looking at character length

## Troubleshooting (3g)

```{r}
as.numeric_possible <- possibly(.f = as.numeric, otherwise = 999)

step2 %>% mutate(temporal_temp = map_dbl(.x = temp, .f = as.numeric_possible)) %>% 
  select(datasheet, house, temp, temporal_temp) %>% 
  filter(temporal_temp == 999)
```

-   The question mark is a subscript i.
-   This is a tricky one to solve unless you go into all those datasheets and fix it,

## Troubleshooting (3h)

-   ut I noticed (using View) that none of the temperatures in the problem sheets were above 99.
-   So we could just take the first 2 digits

```{r}
step2 %>% 
  mutate(temporal_temp = map_dbl(.x = temp, .f = as.numeric_possible)) %>% 
  select(datasheet, house, temp, temporal_temp) %>% 
  filter(!is.na(temp)) %>% 
  filter(temporal_temp == 999 | is.na(temporal_temp)) %>% 
  mutate(temp_numeric = as.numeric(if_else(condition = temporal_temp == 999 | is.na(temporal_temp), 
                                       true = str_sub(string = temp, 1, 2), 
                                       false = temp))) %>% 
  slice(1:10)


```

```{r, echo = FALSE, warning=FALSE}
step3 <- step2 %>%
  mutate(temporal_temp = map_dbl(.x = temp, .f = as.numeric_possible)) %>%
  mutate(temp_numeric = as.numeric(
    case_when(temporal_temp == 999 ~ str_sub(string = temp, 1, 2),
              is.na(temporal_temp) ~ str_sub(string = temp, 1, 2),
              TRUE ~ temp))) %>% 
  mutate(temp_C = 5/9*(temp_numeric - 32))
 # mutate(temp_numeric = as.numeric(if_else(temporal_temp == 999 | is.na(temporal_temp),)
 #                                      true = str_sub(string = temp, 1, 2),
 #                                      false = temp))) 
```

## Next VMC

```{r}
step3 %>% mutate(VMC_numeric = as.numeric(VMC)) %>% filter(is.na(VMC_numeric))

## see if we remove % sign we fix the issue

step3 %>% 
  mutate(VMC_numeric = as.numeric(str_remove_all(string = VMC, pattern = "%"))) %>% 
  filter(!is.na(VMC) & is.na(VMC_numeric)) %>% select(datasheet, contains("VMC"))

## almost 
## fix last few manually

step4 <- step3 %>% mutate(VMC_numeric = as.numeric(str_remove_all(string = VMC, pattern = "%")))
```

## Finally dates and times

```{r}
step4 %>% 
  select(datasheet, date) %>% 
  mutate(date_ymd = mdy(date)) %>% 
  mutate(date_ymd = if_else(is.na(date_ymd), ymd(date), date_ymd)) %>% 
  filter(is.na(date_ymd))
```

-   Few left that would be easiest fix mannually.
-   Almost there. Just times left

## Fixing Times (1)

```{r}
(step4a <- step4 %>% 
  filter(!is.na(start_time) | !is.na(end_time)) %>% 
  select(datasheet, start_time, end_time) %>% 
  mutate(start_time_hm = hm(start_time), 
         end_time_hm = hm(end_time)))
```

## Fixing Times (2)

-   some issues left

```{r}
step4 %>% 
  select(datasheet, start_time, end_time) %>% 
  pivot_longer(names_to = "time_group", values_to = "time", cols = c(start_time:end_time)) %>% 
  filter(!is.na(time)) %>% 
  mutate(time_hm = hm(time)) %>% 
  filter(is.na(time_hm)) %>% 
  mutate(time_hm = if_else(!is.na(time_hm), time_hm, hms(str_remove(time, "1899-12-31")))) %>% 
  filter(is.na(time_hm)) 
```

```{r, eval = FALSE}
step4a %>% 
   mutate(start_time_hm = hms(str_remove(start_time, "1899-12-31")), 
          end_time_hm = hms(str_remove(end_time, "1899-12-31"))) 
  filter(!is.na(start_time) & is.na(start_time_hm))
        #!is.na(end_time) & is.na(end_time_hm)))

## fix these by hand

# final_metadata <- step5 %>% mutate(start_time_hm = hm(start_time), end_time_hm = hm(end_time)) %>% mutate(start = str_remove(start_time, "1899-12-31"), end = str_remove(end_time, "1899-12-31")) %>% mutate(start_time_hm = if_else(is.na(start_time_hm), hms(start),start_time_hm), end_time_hm = if_else(is.na(end_time_hm), hms(end),end_time_hm))

## need to fix some of the column names

#full_count_dataset %>% inner_join(final_metadata) \## this won't work, because the errors that are still in the dataset
```

# Use cleaned up dataset

```{r}
updated_sheet_folder = "C://Users//dajansen3//Box//EC 2023 data by housecode//" 

all_datasheets_cleaned <- list.files(updated_sheet_folder, all.files = TRUE, recursive = TRUE, pattern = "csv")

excel_files_with_csv_extension <-tibble(datasheet = all_datasheets_cleaned) %>% 
  mutate(path_to_sheet = paste0(updated_sheet_folder, datasheet)) %>% 
  mutate(filetype = if_else(str_detect(datasheet, "csv"), "csv", "xlsx")) %>%
  mutate(data = map(.x = path_to_sheet, .f = read_data_possibly_v2)) %>% 
  mutate(nr_rows_in_tibble = map_dbl(.x = data, .f = nrow)) %>% 
  filter(nr_rows_in_tibble == 0) %>% 
  select(datasheet) %>% 
  pull()

combined_cleaned_sheets <- tibble(datasheet = all_datasheets_cleaned) %>% 
  slice(c(175, 190)) %>% 
  mutate(path_to_sheet = paste0(updated_sheet_folder, datasheet)) %>% 
  mutate(filetype = if_else(str_detect(datasheet, "csv"), "csv", "xlsx")) %>%
  mutate(real_filetype = if_else(datasheet %in% excel_files_with_csv_extension, 'xlsx', filetype)) %>% 
  mutate(data = map2(.x = real_filetype, .y = path_to_sheet, .f = read_data_possibly_v4)) %>% 
  mutate(nr_row_on_sheet = map_dbl(.x = data, .f = nrow))

full_count_dataset <- combined_cleaned_sheets %>% unnest(cols = c(data))
full_count_dataset %>% distinct(tick_count)


tibble(datasheet = all_datasheets_cleaned) %>% 
  mutate(path_to_sheet = paste0(updated_sheet_folder, datasheet)) %>% 
  mutate(filetype = if_else(str_detect(datasheet, "csv"), "csv", "xlsx")) %>%
  mutate(real_filetype = if_else(datasheet %in% excel_files_with_csv_extension, 'xlsx', filetype)) %>% 
  mutate(data = map2(.x = real_filetype, .y = path_to_sheet, .f = read_metadata_v1)) %>% 
  mutate(nr_row_on_sheet = map_dbl(.x = data, .f = nrow))
```

## Data control

-   there should be 68 houses \* 20 sheets = 1360
-   filenames contains some info
    -   house
    -   data
    -   treatment

```{r}
## before dealing with all these problems we should check if we have all the data.
house_sheet_info = tibble(datasheet = all_datasheets_cleaned) %>% 
  mutate(info = str_remove_all(datasheet, pattern = '.csv|.xlsx')) %>% 
  mutate(info = str_remove_all(info, pattern = '\\(.*')) %>% 
  mutate(info = str_squish(info)) %>% 
  separate(info, into = c(NA, "house", "year", "month", "day", "treatment"), remove = FALSE) %>% 
  mutate(completed = complete.cases(.)) 

house_sheet_info %>% 
  mutate(date = ymd(paste(year, month, day, sep = "-"))) %>% 
  group_by(house, date) %>% 
  summarise(n())
  
  
house_sheet_info %>% 
  group_by(house, treatment)  %>% 
  summarise(nr_sheets = n()) %>% 
  ungroup() %>% 
  complete(house, treatment) %>% 
  mutate(treatment = forcats::fct_relevel(treatment, "pretreatment")) %>% 
  mutate(nr_sheets = as_factor(nr_sheets)) %>% 
  ggplot(aes(x=treatment, y = house, fill = nr_sheets)) +
    geom_tile() +
    scale_fill_manual(values=c("#fdae61", "#fee08b", "#e6f598", "#abdda4"), na.value = "grey90") +
    cowplot::theme_cowplot() +
    theme(axis.text.x=element_text(angle=45,hjust=1)) 
```

#But we have length(list.files(path = sheet_folder)) (68 \* 20) - length(list.files(path = sheet_folder)) \## are missing

tibble(filename = list.files(path = sheet_folder)) %\>% mutate(house = as.numeric(str_sub(filename, 1, 3))) %\>%\
group_by(house) %\>% summarise(nr_sheets = n()) %\>% summarise(max_nr_sheets = max(nr_sheets), min_nr_sheets = min(nr_sheets), median_nr_sheets = median(nr_sheets))

## the warning is because naming was not consistent

tibble(filename = list.files(path = sheet_folder)) %\>% mutate(house = as.numeric(str_sub(filename, 1, 3))) %\>%\
group_by(house) %\>% summarise(nr_sheets = n()) %\>% group_by(nr_sheets) %\>% summarise(nr_houses = n()) %\>% arrange(-nr_sheets)

## quick side step

## note that here there are NA values, because the tick count was not filled out

## are these all 0 or are the not sampled?

```{r}
list.files()

```
